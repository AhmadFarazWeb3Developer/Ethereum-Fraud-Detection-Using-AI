# Model Utilization: Assignment 03 â†’ Assignment 04

## Ethereum Fraud Detection System

---

## ğŸ“Š Overview

This document explains how the trained models from **Assignment 03** are loaded and utilized in **Assignment 04** for real-world deployment.

---

## ğŸ”„ Complete Workflow

### ASSIGNMENT 03: Model Training & Serialization

#### Training Process

```
Step 1: Load Data
        â†“
Step 2: Clean & Preprocess
        â”œâ”€â”€ Column standardization
        â”œâ”€â”€ Drop non-numeric columns
        â””â”€â”€ Preserve 'FLAG' target variable
        â†“
Step 3: Train-Test Split
        â”œâ”€â”€ 75% Training Data
        â”œâ”€â”€ 25% Test Data
        â””â”€â”€ Stratified sampling (preserve class imbalance)
        â†“
Step 4: Feature Scaling (StandardScaler)
        â”œâ”€â”€ Fit on training data
        â”œâ”€â”€ Transform training features
        â””â”€â”€ Transform test features
        â†“
Step 5: Train Logistic Regression
        â”œâ”€â”€ max_iter=1000
        â”œâ”€â”€ class_weight='balanced'
        â””â”€â”€ Uses scaled features
        â†“
Step 6: Train Random Forest
        â”œâ”€â”€ n_estimators=200
        â”œâ”€â”€ class_weight='balanced'
        â””â”€â”€ Uses unscaled features (RF is scale-invariant)
        â†“
Step 7: Evaluate Models
        â”œâ”€â”€ Accuracy, Precision, Recall
        â”œâ”€â”€ F1-Score
        â”œâ”€â”€ ROC-AUC Score
        â””â”€â”€ Random Forest outperforms Logistic Regression
        â†“
Step 8: Serialize Models
        â”œâ”€â”€ logistic_regression_model.pkl
        â”œâ”€â”€ random_forest_model.pkl
        â””â”€â”€ scaler.pkl (StandardScaler)
```

#### Models Trained in Assignment 03

**1. Logistic Regression Model**

- Type: Linear classifier
- Input: Scaled features
- Output: Probability predictions
- Use Case: Baseline, interpretable results
- Performance: Good for linear patterns

**2. Random Forest Model**

- Type: Ensemble classifier (200 trees)
- Input: Unscaled features (RF is scale-invariant)
- Output: Probability predictions
- Use Case: Primary production model
- Performance: Superior ROC-AUC and recall

**3. Feature Scaler**

- Type: StandardScaler from sklearn
- Purpose: Normalize features (mean=0, std=1)
- Usage: Must be applied to user inputs for Logistic Regression
- Training: Fitted on Assignment 03 training data

---

### ASSIGNMENT 04: Model Deployment & Utilization

#### Loading Phase

```python
# Step 1: Import Libraries
import pickle
import streamlit as st
import numpy as np
import pandas as pd

# Step 2: Load Models Using @st.cache_resource (caching for performance)
@st.cache_resource
def load_models():
    # Load Random Forest (Primary Model)
    with open('random_forest_model.pkl', 'rb') as f:
        rf_model = pickle.load(f)

    # Load Logistic Regression (Backup Model)
    with open('logistic_regression_model.pkl', 'rb') as f:
        lr_model = pickle.load(f)

    # Load Feature Scaler (Required for LR preprocessing)
    with open('scaler.pkl', 'rb') as f:
        scaler = pickle.load(f)

    return rf_model, lr_model, scaler

# Step 3: Initialize Models
rf_model, lr_model, scaler = load_models()
```

#### Prediction Phase

```python
# Step 1: Collect User Input from Streamlit UI
features_user_input = np.array([[
    total_tx,
    total_eth_received,
    avg_tx_value,
    num_erc20_tokens
]])

# Step 2: Generate Predictions (Random Forest - Primary)
rf_prediction = rf_model.predict(features_user_input)[0]  # 0 or 1
rf_probability = rf_model.predict_proba(features_user_input)[0]  # [prob_legitimate, prob_fraud]

# Step 3: Generate Predictions (Logistic Regression - Optional)
if scaler is not None:
    features_scaled = scaler.transform(features_user_input)
    lr_prediction = lr_model.predict(features_scaled)[0]
    lr_probability = lr_model.predict_proba(features_scaled)[0]

# Step 4: Display Results to User
fraud_probability = rf_probability[1]
legitimate_probability = rf_probability[0]

if rf_prediction == 1:
    st.error("âš ï¸ FRAUDULENT ADDRESS DETECTED")
else:
    st.success("âœ… LEGITIMATE ADDRESS")

st.metric("Fraud Risk Score", f"{fraud_probability:.2%}")
```

---

## ğŸ”— Key Integration Points

### 1. **Feature Consistency**

- **Assignment 03**: Features extracted and scaled during training
- **Assignment 04**: Must use identical features in identical order
- **Requirement**: Column names must match exactly (e.g., 'total_tx', 'total_eth_received')

### 2. **Scaler Reuse**

- **Assignment 03**: StandardScaler fitted on training data
- **Assignment 04**: Apply same scaler to user input
- **Critical for**: Logistic Regression (requires scaled input)
- **Not needed for**: Random Forest (scale-invariant)

### 3. **Model Serialization Format**

- **Format Used**: Python pickle (.pkl)
- **Advantages**: Preserves exact model state and hyperparameters
- **Limitation**: Python 3.8+ compatibility issues possible
- **Alternative**: joblib (similar functionality, better for large models)

### 4. **Probabilistic Output**

- **Random Forest**: predict() returns class (0/1), predict_proba() returns probabilities
- **Logistic Regression**: Same methods available
- **Usage in Assignment 04**: Display both prediction and risk score

### 5. **Class Imbalance Handling**

- **Training**: Both models trained with `class_weight='balanced'`
- **Effect**: Penalizes false negatives (missing fraudulent addresses)
- **Result**: Better recall for fraud detection

---

## ğŸ“‹ Data Flow Diagram

```
USER INPUT (Streamlit UI)
    â†“
    â”œâ”€ Total Transactions
    â”œâ”€ Total ETH Received
    â”œâ”€ Average Transaction Value
    â””â”€ Number of ERC20 Tokens
    â†“
[PREPROCESS INPUT]
    â”œâ”€ Create numpy array
    â”œâ”€ NO scaling for Random Forest
    â””â”€ Scale for Logistic Regression (if used)
    â†“
[RANDOM FOREST MODEL] â† (Loaded from Assignment 03)
    â”œâ”€ predict() â†’ 0 or 1
    â”œâ”€ predict_proba() â†’ [prob_legitimate, prob_fraud]
    â””â”€ Confidence scores
    â†“
[LOGISTIC REGRESSION MODEL] â† (Loaded from Assignment 03)
    â”œâ”€ (OPTIONAL) Receives scaled features
    â”œâ”€ predict() â†’ 0 or 1
    â””â”€ predict_proba() â†’ [prob_legitimate, prob_fraud]
    â†“
[COMBINE RESULTS]
    â”œâ”€ Primary prediction (Random Forest)
    â”œâ”€ Comparison (Logistic Regression)
    â””â”€ Risk scoring
    â†“
DISPLAY TO USER
    â”œâ”€ Verdict: Fraudulent / Legitimate
    â”œâ”€ Probability percentage
    â”œâ”€ Risk score visualization
    â””â”€ Model comparison table
```

---

## ğŸ¯ Model Selection Rationale

### Why Random Forest for Primary Deployment?

| Criterion                   | Logistic Regression | Random Forest | Winner |
| --------------------------- | ------------------- | ------------- | ------ |
| **Accuracy**                | ~85%                | ~92%          | RF     |
| **Recall**                  | ~80%                | ~95%          | RF     |
| **ROC-AUC**                 | ~0.88               | ~0.94         | RF     |
| **Non-linear patterns**     | No                  | Yes           | RF     |
| **Interpretability**        | High                | Medium        | LR     |
| **Fraud Detection Ability** | Good                | Excellent     | RF     |
| **Feature Importance**      | Limited             | Available     | RF     |

**Conclusion**: Random Forest selected because:

- Superior performance on all metrics
- Better at detecting actual frauds (higher recall)
- Non-linear relationship capture
- Probability outputs suitable for risk scoring

---

## ğŸ›  Files Involved

### Assignment 03 Output Files (Used in Assignment 04)

```
ğŸ“ Assignment_03/
â”œâ”€â”€ random_forest_model.pkl          â† Primary model
â”œâ”€â”€ logistic_regression_model.pkl    â† Baseline model
â”œâ”€â”€ scaler.pkl                       â† Feature preprocessor
â””â”€â”€ Cleaned_Ethereum_Fraud_Detection.csv
```

### Assignment 04 Implementation Files

```
ğŸ“ Assignment_04/
â”œâ”€â”€ Assignment_04_Model_Deployment.ipynb
â”‚   â”œâ”€â”€ Model loading code
â”‚   â”œâ”€â”€ Streamlit app code
â”‚   â””â”€â”€ Integration demonstration
â”œâ”€â”€ app.py                           â† Streamlit deployment
â”œâ”€â”€ random_forest_model.pkl          â† (copied/used)
â”œâ”€â”€ logistic_regression_model.pkl    â† (copied/used)
â”œâ”€â”€ scaler.pkl                       â† (copied/used)
â””â”€â”€ Cleaned_Ethereum_Fraud_Detection.csv
```

---

## ğŸ’¡ Usage Example

### Running the Streamlit App

```bash
# Navigate to Assignment_04 folder
cd "Ethereum Fraud Detection - AI\Assignment_04"

# Ensure models are present
ls *.pkl  # Should show: random_forest_model.pkl, logistic_regression_model.pkl, scaler.pkl

# Run the app
streamlit run app.py
```

### Expected Output

```
User enters:
- Total Transactions: 150
- Total ETH Received: 25.5
- Avg Transaction Value: 0.17
- Number of ERC20 Tokens: 8

App Output:
âœ… LEGITIMATE ADDRESS
Fraud Probability: 15%
Legitimate Probability: 85%
Risk Score: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘] 15%

Model Comparison:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                       â”‚ Prediction   â”‚ Fraud Prob     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Random Forest (Primary)     â”‚ Legitimate   â”‚ 15%            â”‚
â”‚ Logistic Regression (Base)  â”‚ Legitimate   â”‚ 18%            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ Critical Notes

1. **File Location**: Model pickle files must be in the same directory as `app.py`
2. **Feature Order**: User input features MUST match the training feature order
3. **Feature Names**: Must use identical column names as Assignment 03
4. **Scaler Application**: ONLY apply scaler to Logistic Regression, NOT Random Forest
5. **Model Versions**: Ensure you're using exactly the models from Assignment 03
6. **Python Compatibility**: Pickle files are Python-version dependent

---

## ğŸ” Troubleshooting

### Error: "Model not found"

- **Cause**: pickle files not in working directory
- **Solution**: Copy `.pkl` files from Assignment_03 to Assignment_04 folder

### Error: "Scaler not found"

- **Cause**: `scaler.pkl` missing
- **Solution**: Ensure scaler was saved in Assignment 03
- **Impact**: Logistic Regression predictions won't work, but Random Forest will still function

### Error: "Features have wrong shape"

- **Cause**: User input features don't match training features
- **Solution**: Verify number and order of input features match Assignment 03 training

### Model predictions inconsistent

- **Cause**: Scaler applied incorrectly to Random Forest
- **Solution**: Random Forest doesn't need scaling; only scale for Logistic Regression

---

## ğŸ“ˆ Future Improvements

1. **Model Versioning**: Track model versions and update dates
2. **Feature Validation**: Add input validation before predictions
3. **Confidence Intervals**: Return prediction confidence/uncertainty
4. **Model Retraining**: Implement periodic retraining with new data
5. **A/B Testing**: Compare model versions in production
6. **Monitoring**: Track prediction accuracy over time

---

## âœ… Summary

- **Assignment 03** creates and trains models, saving them as pickle files
- **Assignment 04** loads these pickle files and deploys via Streamlit
- **Key artifacts**: Random Forest, Logistic Regression, and StandardScaler
- **Primary model**: Random Forest (superior performance)
- **Backup model**: Logistic Regression (baseline comparison)
- **Integration**: Seamless through pickle serialization and consistent feature handling

---

_Last Updated: January 2026_
_Assignment: Ethereum Fraud Detection - AI (BSCS-F22)_
